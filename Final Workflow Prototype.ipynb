{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\n",
    "from langchain_community.tools.sql_database.tool import (\n",
    "    InfoSQLDatabaseTool, ListSQLDatabaseTool, QuerySQLCheckerTool, QuerySQLDatabaseTool\n",
    ")\n",
    "from langchain_community.agent_toolkits.sql.base import create_sql_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langgraph.graph.state import StateGraph\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Set API Key and Initialize LLM\n",
    "llm = init_chat_model(model=\"llama3.1:8b\", model_provider=\"ollama\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. temperature controls the randomness of the model's output\n",
    "2. temerature = 0 means it makes max deterministic and focused, \n",
    "3. meaning it will choose the most likely next word each time, \n",
    "4. resulting in less variation and more predictable outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Fetch and Process Files from Folder\n",
    "folder_path = r\"D:\\VSCode Programs\\Final Output\\Database Files\"  # Change to your folder path\n",
    "db_connections = {}  # Stores all database connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for files in: D:\\VSCode Programs\\Final Output\\Database Files...\n",
      "\n",
      "Converting atmspl_trip_details.csv to SQLite...\n",
      "Created database: atmspl_trip_details.db with table 'atmspl_trip_details'\n",
      "Found database: atmspl_trip_details.db\n",
      "Converting Customer Portfolio.csv to SQLite...\n",
      "Created database: Customer_Portfolio.db with table 'Customer_Portfolio'\n",
      "Found database: Customer_Portfolio.db\n",
      "Converting diabetes.csv to SQLite...\n",
      "Created database: diabetes.db with table 'diabetes'\n",
      "Found database: diabetes.db\n",
      "Found database: IFDP.db\n",
      "Converting landmark.csv to SQLite...\n",
      "Created database: landmark.db with table 'landmark'\n",
      "Found database: landmark.db\n",
      "Converting Meeting Updates.csv to SQLite...\n",
      "Created database: Meeting_Updates.db with table 'Meeting_Updates'\n",
      "Found database: Meeting_Updates.db\n",
      "Converting road.csv to SQLite...\n",
      "Created database: road.db with table 'road'\n",
      "Found database: road.db\n",
      "Converting Stock Ageing.csv to SQLite...\n",
      "Created database: Stock_Ageing.db with table 'Stock_Ageing'\n",
      "Found database: Stock_Ageing.db\n",
      "Converting titanic.csv to SQLite...\n",
      "Created database: titanic.db with table 'titanic'\n",
      "Found database: titanic.db\n",
      "Converting tps_trip_details.csv to SQLite...\n",
      "Created database: tps_trip_details.db with table 'tps_trip_details'\n",
      "Found database: tps_trip_details.db\n",
      "Converting Zone Excel.xlsx to SQLite...\n",
      "Processing sheet: Input\n",
      "  Input Max Vessel Size  Ocean Frt  Road Handling  Rake Handing  \\\n",
      "0   KPT            Cape       14.0          475.0         590.0   \n",
      "1   KPT         Panamax        NaN            NaN           NaN   \n",
      "2   Goa  Lightened cape       15.5          340.0         435.0   \n",
      "3   Goa         Panamax       16.0          340.0         435.0   \n",
      "4  NMPT  Lightened cape       14.0          350.0         370.0   \n",
      "\n",
      "   Indo Ocean Frt  RSA Ocean Frt  Aus Ocean Frt  USA Ocean Frt  \n",
      "0             8.0          12.00          12.00           35.0  \n",
      "1             9.5          13.75          13.75            NaN  \n",
      "2            11.0            NaN            NaN            NaN  \n",
      "3            10.0          13.50          13.50            NaN  \n",
      "4             9.5            NaN            NaN            NaN  \n",
      "Created table 'Input' in database: Zone_Excel.db\n",
      "Processing sheet: Budget\n",
      "  Business Segment    Zone          Customer Name  Trader Industry Segment  \\\n",
      "0            Sales  Zone 6        Coastal Energen   Swamy              IPP   \n",
      "1              TPH  Zone 5       Meenakshi Energy    Kasi            Power   \n",
      "2            Sales  Zone 6                  IL&FS  Sriram              IPP   \n",
      "3              TPH  Zone 5  Electrosteel Castings    Kasi       Iron/Steel   \n",
      "4              TPH  Zone 5              Kirloskar    Kasi       Iron/Steel   \n",
      "\n",
      "  Discharge Port Load Port Country          Grade Total Sales  \n",
      "0      Tuticorin              INDO  INDO-4200 GAR     2000000  \n",
      "1  Krishnapatnam               NaN            NaN      600000  \n",
      "2       Karaikal              INDO  INDO-4200 GAR      450000  \n",
      "3  Krishnapatnam               AUS            NaN      300000  \n",
      "4  Krishnapatnam               AUS            NaN      300000  \n",
      "Created table 'Budget' in database: Zone_Excel.db\n",
      "Processing sheet: Meeting Updates\n",
      "   SI No. Meeting Date    Zone Trader Name         Customer Name  \\\n",
      "0       1   2024-11-14  Zone 8       Suraj  MB Sponge / MB Ispat   \n",
      "1       2   2024-11-14  Zone 8       Suraj             CP Sponge   \n",
      "2       3   2024-11-15  Zone 8      Sudesh          Rajshri Iron   \n",
      "3       4   2024-11-15  Zone 8       Suraj           Satyam Iron   \n",
      "4       5   2024-11-15  Zone 8       Suraj        Satyam Smelter   \n",
      "\n",
      "  Name of the person visited  \\\n",
      "0            Arvind Agarwal    \n",
      "1         Kumar Chand Chawla   \n",
      "2            Abhishek Sharma   \n",
      "3              Rahul Agarwal   \n",
      "4              Rajeev Dalmia   \n",
      "\n",
      "                                         Interaction  \\\n",
      "0  Visited their plant. They consume 44 FC domest...   \n",
      "1  Visited their plant. They currently consume 44...   \n",
      "2  Visited their Plant. Currently consumes 45 FC ...   \n",
      "3  Visited their Plant. Currently consumes 44FC d...   \n",
      "4  Visited their Plant. Consumes 44FC domestic co...   \n",
      "\n",
      "                                              Action  \n",
      "0    Expected to be Offering 55NAR Cargo by Jan ’25.  \n",
      "1  Due to the softening price trend in sponge, th...  \n",
      "2  We Offered 55NAR cargo at ₹ 10,450++ at Haldia...  \n",
      "3  Due to softening sponge iron prices, they plan...  \n",
      "4  Expected to operational by March 2025 so we ca...  \n",
      "Created table 'Meeting_Updates' in database: Zone_Excel.db\n",
      "Processing sheet: Updates & Issues\n",
      "   Sr. No.    Zone     Particulars  \\\n",
      "0        1  Zone 5   Sponge Sector   \n",
      "1        2  Zone 5   Cement Sector   \n",
      "2        3  Zone 5             IPP   \n",
      "3        4  Zone 5   Other Updates   \n",
      "4        5  Zone 5  Live Enquiries   \n",
      "\n",
      "                                             Remarks  \n",
      "0  1. Sponge price around Rs. 27000 - 28000 PMT. ...  \n",
      "1  1. No enquiry for US coal. Major Cement produc...  \n",
      "2  1. Private IPPs already slowing down power pro...  \n",
      "3  1. No Major Development in down south Retail M...  \n",
      "4  2. JSW Steels -150 KT, Indo 48, JGD\\n3. MEL - ...  \n",
      "Created table 'Updates_&_Issues' in database: Zone_Excel.db\n",
      "Processing sheet: Dispatch Market Share\n",
      "     Zone      Port Origin  Grade Updating Date AEL dispatch YTD (MT)  \\\n",
      "0  Zone 7       GPL   INDO    NaN    2024-12-05                498967   \n",
      "1  Zone 7       GPL    RSA    NaN    2024-12-05            6455161884   \n",
      "2  Zone 7       GPL    AUS    NaN    2024-12-05                205036   \n",
      "3  Zone 7  GOPALPUR    RSA    NaN    2024-12-05             800001884   \n",
      "4  Zone 8       NaN    NaN    NaN    2024-12-02            1442591.22   \n",
      "\n",
      "  Competitor dispatch YTD (MT) AEL dispatch Current Fortnight (MT)  \\\n",
      "0                      2375552                               27288   \n",
      "1                      3177533                               34053   \n",
      "2                        94471                                4446   \n",
      "3                       374102                                   0   \n",
      "4                      5130862                                 NaN   \n",
      "\n",
      "  Competitor dispatch current fortnight (MT)  Market share  \n",
      "0                                     159141           NaN  \n",
      "1                                     111166           NaN  \n",
      "2                                          0           NaN  \n",
      "3                                      14430           NaN  \n",
      "4                                        NaN           NaN  \n",
      "Created table 'Dispatch_Market_Share' in database: Zone_Excel.db\n",
      "Found database: Zone_Excel.db\n",
      "Conversion complete.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Searching for files in: {folder_path}...\\n\")\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    if file.endswith(\".db\"):\n",
    "        print(f\"Found database: {file}\")\n",
    "        db_name = file.replace(\".db\", \"\")\n",
    "        db_connections[db_name] = SQLDatabase(create_engine(f\"sqlite:///{file_path}\"))\n",
    "    elif file.endswith((\".xlsx\", \".xls\", \".csv\")):\n",
    "        print(f\"Converting {file} to SQLite...\")\n",
    "        db_name = os.path.splitext(file)[0].replace(\" \", \"_\") + \".db\"\n",
    "        db_path = os.path.join(folder_path, db_name)\n",
    "        engine = create_engine(f\"sqlite:///{db_path}\")\n",
    "        \n",
    "        if file.endswith(\".csv\"):\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, encoding='utf-8')\n",
    "            except UnicodeDecodeError:\n",
    "                df = pd.read_csv(file_path, encoding='latin1')\n",
    "            table_name = os.path.splitext(file)[0].replace(\" \", \"_\")\n",
    "            df.to_sql(table_name, con=engine, if_exists=\"replace\", index=False)\n",
    "            print(f\"Created database: {db_name} with table '{table_name}'\")\n",
    "        else:\n",
    "            xls = pd.ExcelFile(file_path)\n",
    "            for sheet_name in xls.sheet_names:\n",
    "                df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "                table_name = sheet_name.replace(\" \", \"_\")\n",
    "                print(f\"Processing sheet: {sheet_name}\")\n",
    "                print(df.head())  # Print the first few rows of the DataFrame to check its content\n",
    "                if not df.empty:\n",
    "                    df.to_sql(table_name, con=engine, if_exists=\"replace\", index=False)\n",
    "                    print(f\"Created table '{table_name}' in database: {db_name}\")\n",
    "                else:\n",
    "                    print(f\"Sheet '{sheet_name}' is empty and will not be added to the database.\")\n",
    "        \n",
    "        db_connections[db_name.replace(\".db\", \"\")] = SQLDatabase(engine)\n",
    "\n",
    "print(\"Conversion complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create SQL Agents for Each Database\n",
    "db_agents = {}\n",
    "for db_name, db in db_connections.items():\n",
    "    toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "    db_agents[db_name] = create_sql_agent(\n",
    "        llm=llm,\n",
    "        toolkit=toolkit,\n",
    "        agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Setting up a toolkit for interacting with an SQL database using a language model\n",
    "2. Leverage the language model to generate SQL queries, interpret results, \n",
    "3. Or perform other database-related tasks more efficiently\n",
    "4. list_tables_tool = ListSQLDatabaseTool(db=db): tool to list/display tables names in your SQL database\n",
    "5. InfoSQLDatabaseTool(db=db): detailed information about DB, such as schema details, table structures, metadata\n",
    "6. QuerySQLCheckerTool(db=db, llm=llm): validate or analyze SQL queries to ensure they are correct and optimized\n",
    "7. QuerySQLDatabaseTool(db=db): facilitate running queries and retrieving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching tables for atmspl_trip_details...\n",
      "Schema retrieved for atmspl_trip_details in atmspl_trip_details\n",
      "\n",
      "Fetching tables for Customer_Portfolio...\n",
      "Schema retrieved for Customer_Portfolio in Customer_Portfolio\n",
      "\n",
      "Fetching tables for diabetes...\n",
      "Schema retrieved for diabetes in diabetes\n",
      "\n",
      "Fetching tables for IFDP...\n",
      "Schema retrieved for Coal_IFDP_Daily_Index_Accuracy_Table in IFDP\n",
      "Schema retrieved for Coal_IFDP_Dynamic_Pricing_MAP_Actual_Pred in IFDP\n",
      "Schema retrieved for Coal_IFDP_Historic_Pricing_Monthly in IFDP\n",
      "\n",
      "Fetching tables for landmark...\n",
      "Schema retrieved for landmark in landmark\n",
      "\n",
      "Fetching tables for Meeting_Updates...\n",
      "Schema retrieved for Meeting_Updates in Meeting_Updates\n",
      "\n",
      "Fetching tables for road...\n",
      "Schema retrieved for road in road\n",
      "\n",
      "Fetching tables for Stock_Ageing...\n",
      "Schema retrieved for Stock_Ageing in Stock_Ageing\n",
      "\n",
      "Fetching tables for titanic...\n",
      "Schema retrieved for titanic in titanic\n",
      "\n",
      "Fetching tables for tps_trip_details...\n",
      "Schema retrieved for tps_trip_details in tps_trip_details\n",
      "\n",
      "Fetching tables for Zone_Excel...\n",
      "Schema retrieved for Budget in Zone_Excel\n",
      "Schema retrieved for Dispatch_Market_Share in Zone_Excel\n",
      "Schema retrieved for Input in Zone_Excel\n",
      "Schema retrieved for Meeting_Updates in Zone_Excel\n",
      "Schema retrieved for Updates_&_Issues in Zone_Excel\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Fetch Schema Information\n",
    "schema_info = {}\n",
    "for db_name, db in db_connections.items():\n",
    "    print(f\"\\nFetching tables for {db_name}...\")\n",
    "    list_tables_tool = ListSQLDatabaseTool(db=db)\n",
    "    tables = list_tables_tool.run(\"\")\n",
    "    schema_info[db_name] = {}\n",
    "    for table in tables.split(\", \"):\n",
    "        info_tool = InfoSQLDatabaseTool(db=db)\n",
    "        schema_info[db_name][table] = info_tool.run(table)\n",
    "        print(f\"Schema retrieved for {table} in {db_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\intern.ai5\\AppData\\Roaming\\Python\\Python311\\site-packages\\pydantic\\_internal\\_fields.py:192: UserWarning: Field name \"schema\" in \"QueryState\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Create LangGraph Query State Schema\n",
    "class QueryState(BaseModel):\n",
    "    query: str\n",
    "    selected_db: str = None\n",
    "    schema: dict = None\n",
    "    sql_query: str = None\n",
    "    validated_sql: str = None\n",
    "    result: str = None\n",
    "    chatbot_response: str = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QueryState class is used to define the structure of the state that will be passed through each step of your workflow. Here’s why each part is important:\n",
    "1. BaseModel: This is likely from Pydantic, a library that helps with data validation and settings management using Python type annotations. It helps in easily serialized to JSON or dictionaries, Data Parsing and reading JSON Schema useful for documentation.\n",
    "2. query: str: This field stores the natural language query provided by the user.\n",
    "3. schema: dict: This field holds the database schema information, which is necessary for generating the correct SQL query.\n",
    "4. sql_query: str = None: This field will store the SQL query generated from the natural language query. It’s initialized to None because it will be populated later in the workflow.\n",
    "5. validated_sql: str = None: This field will store the validated SQL query after it has been checked for correctness. It’s also initialized to None for the same reason.\n",
    "6. result: str = None: This field will store the result of the executed SQL query. Again, it’s initialized to None because it will be populated in the final step of the workflow.\n",
    "7. chatbot_response: str = None: This new field will store the dynamically generated chatbot response based on the query and result. It’s initialized to None because it will be populated after the response is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Define Execution Flow\n",
    "workflow = StateGraph(QueryState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StateGraph: A class used to define the execution flow of the workflow, initialized with the QueryState schema.\n",
    "\n",
    "It is a part of langgraph framework and is used to define, structure and execute the workflows based on state transitions. It act as a Flowchart Engine where:\n",
    "1. Each node represents a function that transforms data. \n",
    "2. Edges define the sequence in which nodes execute.\n",
    "3. state (data structure) is passed between nodes and updated at each step.\n",
    "\n",
    "In the following code, it works as:\n",
    "1. Creates a new state-based graph where Query state is the data strycture that holds information at every step, which means that all nodes in the graph will receive and return an object of type QueryState."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1 & set2)\n",
    "    union = len(set1 | set2)\n",
    "    return intersection / union if union else 0\n",
    "\n",
    "def select_database(state: QueryState) -> QueryState:\n",
    "    \"\"\"Determine the best database and table based on \n",
    "    Jaccard similarity with table and column names.\"\"\"\n",
    "    query_terms = set(re.findall(r'\\b\\w+\\b', state.query.lower()))\n",
    "    db_scores = {}\n",
    "    table_scores = {}\n",
    "\n",
    "    for db_name, tables in schema_info.items():\n",
    "        max_table_score = 0\n",
    "        best_table = None\n",
    "        for table, schema in tables.items():\n",
    "            table_terms = set(table.lower().split(\"_\"))\n",
    "            table_score = jaccard_similarity(query_terms, table_terms)\n",
    "            column_terms = set(re.findall(r'\\b\\w+\\b', schema.lower()))\n",
    "            column_score = jaccard_similarity(query_terms, column_terms)\n",
    "            total_score = max(table_score, column_score)\n",
    "            \n",
    "            if total_score > max_table_score:\n",
    "                max_table_score = total_score\n",
    "                best_table = table\n",
    "\n",
    "        db_scores[db_name] = max_table_score\n",
    "        table_scores[db_name] = best_table\n",
    "\n",
    "    selected_db = max(db_scores, key=db_scores.get)\n",
    "    selected_table = table_scores[selected_db]\n",
    "    print(f\"Database selected: {selected_db}\")\n",
    "    print(f\"Table selected: {selected_table}\")\n",
    "    return QueryState(query=state.query, selected_db=selected_db, selected_table=selected_table, schema=schema_info[selected_db])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This function is a part of LangGraph execution workflow and is responsible for retrieving DB Schema.\n",
    "2. \"state: QueryState\": takes a single argument, state whih is an instance of QueryState Class.\n",
    "3. \" -> Query State\": type hint (->) indicates that the function returns an instance of QueryState.\n",
    "4. type hint (->): Indicate what type of value the function returns. Helps in code readability and debugging. It won't hamper the flow of code but for debug, readable, structured.\n",
    "5. \"return ...\": It returns an instance of QueryState class.\n",
    "6. \"query = state.query\": Keeps the original user query unchanged\n",
    "7. \"selected_db & selected_table\": Based on Jaccard Similarity between User Query and Database Schema, Database and Table is being selected.\n",
    "8. \"schema = schema_info[selected_db]\": Assigns the schema_info dictionary which contains schema details of the selected database tables to the schema attribute of new QueryState object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql(state: QueryState) -> QueryState:\n",
    "    \"\"\"Generate SQL query from the user's query.\"\"\"\n",
    "    sql_query = llm.invoke(f\"\"\"\n",
    "        Convert this natural language query into SQL:\n",
    "        === DATABASE SCHEMA ===\n",
    "        {state.schema}  \n",
    "        === USER QUESTION ===\n",
    "        \"{state.query}\"\n",
    "        - Database name and column names can be same.\n",
    "        - Ensure all relevant columns are considered\n",
    "        - Do not write column name instead of table name. It generally happens when database table with large number of column names are present.\n",
    "        - Use appropriate Filtering if the query implies conditions.\n",
    "        Return only the SQL query.\"\"\").content.strip()\n",
    "    return QueryState(query=state.query, selected_db=state.selected_db, schema=state.schema, sql_query=sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate_sql is responsible for converting Natural Language to SQL using a LLM. It takes a QueryState object as input , it generates an SQL Query based on the database schema, and returns a new QueryState object containing the generate SQL.\n",
    "\n",
    "1. \"state:QueryState\": Takes Single Argument, state, which is an instanc of QueryState.\n",
    "2. \"-> Query State\": With type hint, it indicates the function returns an instance of QueryState.\n",
    "3. llm.invoke: It calls the LLM to convert NL to SQL. state.schema helps LLM to understand DB Structures, state.query is the question asked by user.\n",
    "4. content.strip(): It extract and cleans uneccessary white space.\n",
    "5. query = state.query: Keeps the original user query\n",
    "6. schema = state.schema: Retains the database schema\n",
    "7. sql_query: Stores the generated Query.\n",
    "\n",
    "This ensures that the next step in the Workflow (SQL Validation) gets a properly formatted SQL Query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_sql(state: QueryState) -> QueryState:\n",
    "    db = db_connections[state.selected_db]\n",
    "    valid_columns = set()\n",
    "    for schema in state.schema.values():\n",
    "        valid_columns.update(re.findall(r'(\\w+)\\s\\w+', schema))\n",
    "\n",
    "    query_columns = set(re.findall(r'\\bw+\\b', state.sql_query.lower()))\n",
    "    missing_columns = query_columns - valid_columns\n",
    "\n",
    "    if missing_columns: \n",
    "        raise ValueError(\"Invalid columns in query: {missing_columns}\")\n",
    "    checker_tool = QuerySQLCheckerTool(db=db, llm=llm)\n",
    "    validated_sql = checker_tool.run(state.sql_query)\n",
    "    return QueryState(query=state.query, selected_db=state.selected_db, schema=state.schema, sql_query=state.sql_query, validated_sql=validated_sql)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validate_sql is responsible for checking wheether the generated SQL query is valid before executing it. This helps prevent errors by ensuring that SQL Syntax and structure are correct.\n",
    "\n",
    "1. \"state: StateQuery\": Takes QueryState object as input.\n",
    "2. \"-> QueryState\": Returns a QueryState object as output.\n",
    "3. \"re.findall(r'\\bw+\\b', VARIABLE)\": Finds all sequences of word characters followed by a space and another word in the given VARIABLE string.\n",
    "4. checker_tool.run(state.sql_query): Calls the validation tool to check if state.sql_query is correct. state.sql_query is the query generate in generate_sql Function.\n",
    "5. Return a new QueryState object with output parameters.\n",
    "6. query = state.query: Keeps the original user question.\n",
    "7. schema = state.schema: Retains the database schema.\n",
    "8. sql_query = state.sql_query: Stores the generated SQL Query.\n",
    "9. validated_sql = validated_sql: Stores the validated SQL or error message.\n",
    "\n",
    "This ensures that only correct SQL queries are processed to the next step execute_sql."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(state: QueryState) -> QueryState:\n",
    "    \"\"\"Execute the SQL query and fetch results.\"\"\"\n",
    "    query_tool = QuerySQLDatabaseTool(db=db_connections[state.selected_db])\n",
    "    result = query_tool.run(state.validated_sql)\n",
    "    return QueryState(query=state.query, selected_db=state.selected_db, schema=state.schema, sql_query=state.sql_query, validated_sql=state.validated_sql, result=result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "execute_sql function is responsible for the validated SQL query on the connected database and Retrieving the results. It ensures that only validated SQL queries are run, prevnting errors and DB crashes.\n",
    "\n",
    "1. \"state: QueryState\": Accepts a QueryState object as input.\n",
    "2. \"-> QueryState\": Returns a QueryState object as Output.\n",
    "3. query_tool.run(state.validated_sql): Runs Validated SQL Query on DB. Contains the SQL query that passed validation in validate_sql. Query as Input in this Function and Data Value as output.\n",
    "4. query = state.query: Keeps the original user question.\n",
    "5. schema = state.schema: Retains the database schema.\n",
    "6. sql_query = state.sql_query: Stores the generated SQL Query.\n",
    "7. validated_sql = state.validated_sql: Keeps the validated SQL query.\n",
    "8. result=result: Stores the executed query's result.\n",
    "\n",
    "This ensures that the next step (format_chatbot_response) gets the correct result to generate NL Response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_chatbot_response(state: QueryState) -> QueryState:\n",
    "    \"\"\"Generate a chatbot response based on the query and result.\"\"\"\n",
    "    chatbot_response = llm.invoke(f\"\"\"\n",
    "        You are a chatbot. Given the following user query and SQL result, generate a natural conversational response.\n",
    "        === USER QUESTION ===\n",
    "        {state.query}\n",
    "        === SQL RESULT ===\n",
    "        {state.result}\n",
    "        Provide a user-friendly response.\n",
    "    \"\"\").content.strip()\n",
    "    return QueryState(query=state.query, selected_db=state.selected_db, schema=state.schema, sql_query=state.sql_query, validated_sql=state.validated_sql, result=state.result, chatbot_response=chatbot_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function generates human-friendly response based on the SQL Query results, where QueryState is given as input object to the format_chatbot_response and \"-> QueryState\" will return a new QueryStateObject.\n",
    "\n",
    "1. llm.invoke: Calls the LLM to process the given prompt.The prompt is firmatted text that instructs the LLM on how to generate the chatbot response. Instruct LLM to behave as ChatBot and provide NL {state.query}, result {state.result} and instruct to provide user friendly response in a prompt. \n",
    "2. .content: Extracts the actual text response generated by LLM. \n",
    "3. .strip(): Removes any unnecessary leading or trailing whitespace.\n",
    "4. chatbot_response: Stores a well-formatted, NL response based on the SQL Results.\n",
    "5. \"return ...\": A new QueryState object is created with query, schema, sql_query, validated_sql, result as before. The new chat_response, now contains a human friendly message. \n",
    "\n",
    "This function does not modify the original state object. Instead, it creates a new QueryState ubstabce with the updated chatbot response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code QueryState is a Class which means it is here a Data Model that defines attributes, data types, default values. Object of a class is created when you call a function as object(instance) ==> QueryState(BaseModel), here as state: QueryState(...) is written, so state holds the object which holds specific data. It is updated everytime when it is told to. \n",
    "\n",
    "1. Class is a blueprint which defines what data it should hold.\n",
    "2. Object is an actual instance of that blueprint with specific values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_node(\"select_database\", select_database)\n",
    "workflow.add_node(\"generate_sql\", generate_sql)\n",
    "workflow.add_node(\"validate_sql\", validate_sql)\n",
    "workflow.add_node(\"execute_sql\", execute_sql)\n",
    "workflow.add_node(\"format_response\", format_chatbot_response)\n",
    "\n",
    "workflow.set_entry_point(\"select_database\")\n",
    "workflow.add_edge(\"select_database\", \"generate_sql\")\n",
    "workflow.add_edge(\"generate_sql\", \"validate_sql\")\n",
    "workflow.add_edge(\"validate_sql\", \"execute_sql\")\n",
    "workflow.add_edge(\"execute_sql\", \"format_response\")\n",
    "\n",
    "executor = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes are added to the fraph to define execution order. The process flows from Retrieving Schema --> Generating SQL --> Executing SQL --> Formatting the Chatbot Response.\n",
    "\n",
    "Then, Compile the workflow for execution.\n",
    "1. add_node(\"name\", function): A method to add a step function to the workflow. \"name\" is the string identifier for the step. function is the actual identifier for the step.\n",
    "2. \"get_schema\", \"generate_sql\", \"validate_sql\", \"execute_sql\": Names of the nodes.\n",
    "3. get_schema, generate_sql, validate_sql, execute_sql: Corresponding step functions.\n",
    "4. set_entry_point: First step in the workflow, from where execution begins. \n",
    "5. add_edge(\"A\",\"B\"): It connects 2 steps ensuring one executes after the other between two \"name\". It allows dynamic workflow as per individual's design.\n",
    "\n",
    "Why name is in  quotes (\" \")?\n",
    "name is the string identifier for the step. Whereas, function is the actual function that performs the step. It is not the actual function but a reference name for tracking the step. It allows to refer to each step by name when setting up the execution order.\n",
    "\n",
    "Why not just use function names directly?\n",
    "\"name\" allows us to easily modify and reference steps without calling function names. Function can have identical names accirss dufferent workflows, but \"name\" ebsures unique identification within the StateGraph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\intern.ai5\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\components\\chatbot.py:285: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database selected: IFDP\n",
      "Table selected: Coal_IFDP_Daily_Index_Accuracy_Table\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Define the function to handle the chatbot interaction\n",
    "def chatbot_response(history, user_query):\n",
    "    if user_query.lower() == \"exit\":\n",
    "        return history + [(\"User\", user_query), (\"Chatbot\", \"Chatbot: quits\")], history, \"\"\n",
    "    result = executor.invoke(QueryState(query=user_query))\n",
    "    response = result['chatbot_response']\n",
    "    return history + [(\"User\", user_query), (\"Chatbot\", response)], history, \"\"\n",
    "\n",
    "# Custom CSS for styling\n",
    "custom_css = \"\"\"\n",
    "#chatbot {\n",
    "    background-color: #f5f5f5;\n",
    "    border-radius: 10px;\n",
    "    padding: 10px;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Create the Gradio interface\n",
    "iface = gr.Blocks(css=custom_css)\n",
    "\n",
    "with iface:\n",
    "    gr.Markdown(\"# SQL Chatbot\")\n",
    "    gr.Markdown(\"Ask me anything about your databases!\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    state = gr.State([])\n",
    "    with gr.Row():\n",
    "        txt = gr.Textbox(show_label=False, placeholder=\"Type your message here...\")\n",
    "        txt.submit(chatbot_response, [state, txt], [chatbot, state, txt])\n",
    "\n",
    "# Launch the Gradio interface\n",
    "iface.launch()\n",
    "\n",
    "# Ensure the rest of your code is included here, especially the workflow and executor setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWhat was the average forecast for API4 in March 2024 in IFDP? 97.73\\nhow many male survived in titanic? 109\\nIn which district, Suratgarh Junction is located in Landmarks? HANUMANGARH\\nWhat is the total running average speed of all TPS in TPS Trips? 21.35km/h\\nHow many transporter ar ATMSL? \\nwagon id of id = 10036288? first row of atmsl \\nGive me all the Customer Name of Zone 5\\nWhat is the average of QTY in MT\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "What was the average forecast for API4 in March 2024 in IFDP? 97.73\n",
    "how many male survived in titanic? 109\n",
    "In which district, Suratgarh Junction is located in Landmarks? HANUMANGARH\n",
    "What is the total running average speed of all TPS in TPS Trips? 21.35km/h\n",
    "How many transporter ar ATMSL? \n",
    "wagon id of id = 10036288? first row of atmsl \n",
    "Give me all the Customer Name of Zone 5\n",
    "What is the average of QTY in MT\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Textbox' object has no attribute 'style'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m     state \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mState([])\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m gr\u001b[38;5;241m.\u001b[39mRow():\n\u001b[1;32m---> 29\u001b[0m         txt \u001b[38;5;241m=\u001b[39m \u001b[43mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshow_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplaceholder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mType your message here...\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstyle\u001b[49m(container\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m         txt\u001b[38;5;241m.\u001b[39msubmit(chatbot_response, [state, txt], [chatbot, state])\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Launch the Gradio interface\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Textbox' object has no attribute 'style'"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_query = input(\"You: \")\n",
    "    if user_query.lower() == \"exit\":\n",
    "        print(\"Chatbot: quits\")\n",
    "        break\n",
    "    result = executor.invoke(QueryState(query=user_query))\n",
    "    print(\"You:\", user_query)\n",
    "    print(\"\\nChatbot:\", result['chatbot_response'])\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "# Can be deployed on Streamlit, Gradio, Sharepoint etc. Depending upon the situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database selected: IFDP\n",
      "Table selected: Coal_IFDP_Daily_Index_Accuracy_Table\n",
      "\n",
      "Chatbot Response: {'query': 'What was the average forecast for API4 in March 2024', 'selected_db': 'IFDP', 'schema': {'Coal_IFDP_Daily_Index_Accuracy_Table': '\\nCREATE TABLE \"Coal_IFDP_Daily_Index_Accuracy_Table\" (\\n\\tindex_id INTEGER, \\n\\tindex_name TEXT, \\n\\tdate TEXT, \\n\\tactuals REAL, \\n\\tforecast REAL, \\n\\tmape REAL, \\n\\taccuracy REAL, \\n\\tcreated_at TEXT, \\n\\tid INTEGER, \\n\\tPRIMARY KEY (id)\\n)\\n\\n/*\\n3 rows from Coal_IFDP_Daily_Index_Accuracy_Table table:\\nindex_id\\tindex_name\\tdate\\tactuals\\tforecast\\tmape\\taccuracy\\tcreated_at\\tid\\n1\\tAPI4\\t2024-03-01 00:00:00.000\\t93.38\\t92.48\\t0.96\\t99.04\\t2024-03-01 00:00:00.000\\t251\\n1\\tAPI4\\t2024-03-04 00:00:00.000\\t93.29\\t93.87\\t0.63\\t99.37\\t2024-03-04 00:00:00.000\\t252\\n1\\tAPI4\\t2024-03-05 00:00:00.000\\t94.32\\t93.67\\t0.69\\t99.31\\t2024-03-05 00:00:00.000\\t253\\n*/', 'Coal_IFDP_Dynamic_Pricing_MAP_Actual_Pred': '\\nCREATE TABLE \"Coal_IFDP_Dynamic_Pricing_MAP_Actual_Pred\" (\\n\\tdate DATE, \\n\\tcategories VARCHAR(100), \\n\\tmap FLOAT, \\n\\tmodel_prediction FLOAT, \\n\\tport VARCHAR(100)\\n)\\n\\n/*\\n3 rows from Coal_IFDP_Dynamic_Pricing_MAP_Actual_Pred table:\\ndate\\tcategories\\tmap\\tmodel_prediction\\tport\\n2025-01-10\\tJHN_3800_S\\t5525.0\\t5484.74\\tHazira\\n2025-01-10\\tBISMBSS_3200_S\\t4200.0\\t4181.42\\tHazira\\n2025-01-10\\tKUTAI_4200_P_A\\t6150.0\\t6213.33\\tHazira\\n*/', 'Coal_IFDP_Historic_Pricing_Monthly': '\\nCREATE TABLE \"Coal_IFDP_Historic_Pricing_Monthly\" (\\n\\tid INTEGER, \\n\\t\"Index_Id\" INTEGER NOT NULL, \\n\\t\"Index_Name\" TEXT, \\n\\t\"Monthly_Change\" REAL, \\n\\t\"Month\" TEXT, \\n\\t\"Monthly_Forecast\" REAL, \\n\\t\"Standing_On_Date\" TEXT, \\n\\tPRIMARY KEY (id)\\n)\\n\\n/*\\n3 rows from Coal_IFDP_Historic_Pricing_Monthly table:\\nid\\tIndex_Id\\tIndex_Name\\tMonthly_Change\\tMonth\\tMonthly_Forecast\\tStanding_On_Date\\n39\\t2\\tICI4200\\t1.51\\tMay\\t56.02\\t2024-05-30 00:00:00.000\\n40\\t2\\tICI4200\\t0.0\\tJune\\t55.73\\t2024-05-30 00:00:00.000\\n41\\t2\\tICI4200\\t0.0\\tJuly\\t54.81\\t2024-05-30 00:00:00.000\\n*/'}, 'sql_query': \"```sql\\nSELECT AVG(forecast) \\nFROM Coal_IFDP_Daily_Index_Accuracy_Table \\nWHERE index_name = 'API4' AND date LIKE '%2024-03-%';\\n```\", 'validated_sql': \"SELECT AVG(forecast) \\nFROM Coal_IFDP_Daily_Index_Accuracy_Table \\nWHERE index_name = 'API4' AND date LIKE '%2024-03-%';\", 'result': '[(97.7305,)]', 'chatbot_response': \"The average forecast for API4 in March 2024 was approximately 97.73 degrees! That's quite warm, isn't it? Would you like to know more about the temperature trends or compare it with other months?\"}\n"
     ]
    }
   ],
   "source": [
    "user_query = \"What was the average forecast for API4 in March 2024\"\n",
    "result = executor.invoke(QueryState(query=user_query))\n",
    "print(\"\\nChatbot Response:\", result)\n",
    "# Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database selected: Zone_Excel\n",
      "Table selected: Budget\n",
      "\n",
      "Chatbot Response: {'query': 'What is the Total Sales of Coastal Engergen in Zone 6 whose Discharge Port was Tuticorin', 'selected_db': 'Zone_Excel', 'schema': {'Budget': '\\nCREATE TABLE \"Budget\" (\\n\\t\"Business Segment\" TEXT, \\n\\t\"Zone\" TEXT, \\n\\t\"Customer Name\" TEXT, \\n\\t\"Trader\" TEXT, \\n\\t\"Industry Segment\" TEXT, \\n\\t\"Discharge Port\" TEXT, \\n\\t\"Load Port Country\" TEXT, \\n\\t\"Grade\" TEXT, \\n\\t\"Total Sales\" TEXT\\n)\\n\\n/*\\n3 rows from Budget table:\\nBusiness Segment\\tZone\\tCustomer Name\\tTrader\\tIndustry Segment\\tDischarge Port\\tLoad Port Country\\tGrade\\tTotal Sales\\nSales\\tZone 6\\tCoastal Energen\\tSwamy\\tIPP\\tTuticorin\\tINDO\\tINDO-4200 GAR\\t2000000\\nTPH\\tZone 5\\tMeenakshi Energy\\tKasi\\tPower\\tKrishnapatnam\\tNone\\tNone\\t600000\\nSales\\tZone 6\\tIL&FS\\tSriram\\tIPP\\tKaraikal\\tINDO\\tINDO-4200 GAR\\t450000\\n*/', 'Dispatch_Market_Share': '\\nCREATE TABLE \"Dispatch_Market_Share\" (\\n\\t\"Zone\" TEXT, \\n\\t\"Port\" TEXT, \\n\\t\"Origin\" TEXT, \\n\\t\"Grade\" FLOAT, \\n\\t\"Updating Date\" DATETIME, \\n\\t\"AEL dispatch YTD (MT)\" TEXT, \\n\\t\"Competitor dispatch YTD (MT)\" TEXT, \\n\\t\"AEL dispatch Current Fortnight (MT)\" TEXT, \\n\\t\"Competitor dispatch current fortnight (MT)\" TEXT, \\n\\t\"Market share\" FLOAT\\n)\\n\\n/*\\n3 rows from Dispatch_Market_Share table:\\nZone\\tPort\\tOrigin\\tGrade\\tUpdating Date\\tAEL dispatch YTD (MT)\\tCompetitor dispatch YTD (MT)\\tAEL dispatch Current Fortnight (MT)\\tCompetitor dispatch current fortnight (MT)\\tMarket share\\nZone 7\\tGPL\\tINDO\\tNone\\t2024-12-05 00:00:00\\t498967\\t2375552\\t27288\\t159141\\tNone\\nZone 7\\tGPL\\tRSA\\tNone\\t2024-12-05 00:00:00\\t6455161884\\t3177533\\t34053\\t111166\\tNone\\nZone 7\\tGPL\\tAUS\\tNone\\t2024-12-05 00:00:00\\t205036\\t94471\\t4446\\t0\\tNone\\n*/', 'Input': '\\nCREATE TABLE \"Input\" (\\n\\t\"Input\" TEXT, \\n\\t\"Max Vessel Size\" TEXT, \\n\\t\"Ocean Frt\" FLOAT, \\n\\t\"Road Handling\" FLOAT, \\n\\t\"Rake Handing\" FLOAT, \\n\\t\"Indo Ocean Frt\" FLOAT, \\n\\t\"RSA Ocean Frt\" FLOAT, \\n\\t\"Aus Ocean Frt\" FLOAT, \\n\\t\"USA Ocean Frt\" FLOAT\\n)\\n\\n/*\\n3 rows from Input table:\\nInput\\tMax Vessel Size\\tOcean Frt\\tRoad Handling\\tRake Handing\\tIndo Ocean Frt\\tRSA Ocean Frt\\tAus Ocean Frt\\tUSA Ocean Frt\\nKPT\\tCape\\t14.0\\t475.0\\t590.0\\t8.0\\t12.0\\t12.0\\t35.0\\nKPT\\tPanamax\\tNone\\tNone\\tNone\\t9.5\\t13.75\\t13.75\\tNone\\nGoa\\tLightened cape\\t15.5\\t340.0\\t435.0\\t11.0\\tNone\\tNone\\tNone\\n*/', 'Meeting_Updates': '\\nCREATE TABLE \"Meeting_Updates\" (\\n\\t\"SI No.\" BIGINT, \\n\\t\"Meeting Date\" DATETIME, \\n\\t\"Zone\" TEXT, \\n\\t\"Trader Name\" TEXT, \\n\\t\"Customer Name\" TEXT, \\n\\t\"Name of the person visited\" TEXT, \\n\\t\"Interaction\" TEXT, \\n\\t\"Action\" TEXT\\n)\\n\\n/*\\n3 rows from Meeting_Updates table:\\nSI No.\\tMeeting Date\\tZone\\tTrader Name\\tCustomer Name\\tName of the person visited\\tInteraction\\tAction\\n1\\t2024-11-14 00:00:00\\tZone 8\\tSuraj\\tMB Sponge / MB Ispat\\tArvind Agarwal \\tVisited their plant. They consume 44 FC domestic coal at a landed cost of ₹8,400. They are setting u\\tExpected to be Offering 55NAR Cargo by Jan ’25.\\n2\\t2024-11-14 00:00:00\\tZone 8\\tSuraj\\tCP Sponge\\tKumar Chand Chawla\\tVisited their plant. They currently consume 44 FC domestic coal at a landed cost of ₹8,400 for a 100\\tDue to the softening price trend in sponge, the buyer intends to continue with domestic coal consump\\n3\\t2024-11-15 00:00:00\\tZone 8\\tSudesh\\tRajshri Iron\\tAbhishek Sharma\\tVisited their Plant. Currently consumes 45 FC domestic coal @ landed cost of ₹ 8100 for a 200 TPD ki\\tWe Offered 55NAR cargo at ₹ 10,450++ at Haldia from Dec ‘24 Ld vsl for road delivery. \\xa0Buyer also op\\n*/', 'Updates_&_Issues': '\\nCREATE TABLE \"Updates_&_Issues\" (\\n\\t\"Sr. No.\" BIGINT, \\n\\t\"Zone\" TEXT, \\n\\t\"Particulars\" TEXT, \\n\\t\"Remarks\" TEXT\\n)\\n\\n/*\\n3 rows from Updates_&_Issues table:\\nSr. No.\\tZone\\tParticulars\\tRemarks\\n1\\tZone 5\\tSponge Sector\\t1. Sponge price around Rs. 27000 - 28000 PMT. Demand has been increased, plants are running at profi\\n2\\tZone 5\\tCement Sector\\t1. No enquiry for US coal. Major Cement producers have covered with Pet coke for next 2 months\\n\\n2.Co\\n3\\tZone 5\\tIPP\\t1. Private IPPs already slowing down power production, due to low demand owning to monsoons and shif\\n*/'}, 'sql_query': '```sql\\nSELECT \"Total Sales\"\\nFROM Budget\\nWHERE \"Business Segment\" = \\'Sales\\'\\n  AND \"Zone\" = \\'Zone 6\\'\\n  AND \"Customer Name\" = \\'Coastal Energen\\'\\n  AND \"Discharge Port\" = \\'Tuticorin\\';\\n```', 'validated_sql': 'SELECT \"Total Sales\"\\nFROM Budget\\nWHERE \"Business Segment\" = \\'Sales\\'\\n  AND \"Zone\" = \\'Zone 6\\'\\n  AND \"Customer Name\" = \\'Coastal Energen\\'\\n  AND \"Discharge Port\" = \\'Tuticorin\\';', 'result': \"[('2000000',)]\", 'chatbot_response': 'The total sales for Coastal Energy in Zone 6 with a discharge port at Tuticorin is $2,000,000. Would you like to know more about their sales performance or compare it with other zones?'}\n"
     ]
    }
   ],
   "source": [
    "user_query = \"What is the Total Sales of Coastal Engergen in Zone 6 whose Discharge Port was Tuticorin\"\n",
    "result = executor.invoke(QueryState(query=user_query))\n",
    "print(\"\\nChatbot Response:\", result)\n",
    "# Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database selected: Meeting_Updates\n",
      "Table selected: Meeting_Updates\n",
      "\n",
      "Chatbot Response: {'query': 'On 15 Nov 2024, What were the Action when Rajeev Dalmia Visited', 'selected_db': 'Meeting_Updates', 'schema': {'Meeting_Updates': '\\nCREATE TABLE \"Meeting_Updates\" (\\n\\t\"SI No.\" TEXT, \\n\\t\"Meeting Date\" TEXT, \\n\\t\"Zone\" TEXT, \\n\\t\"Trader Name\" TEXT, \\n\\t\"Customer Name\" TEXT, \\n\\t\"Name of the person visited\" TEXT, \\n\\t\"Interaction\" TEXT, \\n\\t\"Action\" TEXT\\n)\\n\\n/*\\n3 rows from Meeting_Updates table:\\nSI No.\\tMeeting Date\\tZone\\tTrader Name\\tCustomer Name\\tName of the person visited\\tInteraction\\tAction\\n1\\t14-Nov-24\\tZone 8\\tSuraj\\tMB Sponge / MB Ispat\\tArvind Agarwal \\tVisited their plant. They consume 44 FC domestic coal at a landed cost of ?8,400. They are setting u\\tExpected to be Offering 55NAR Cargo by Jan \\x9225.\\n2\\t14-Nov-24\\tZone 8\\tSuraj\\tCP Sponge\\tKumar Chand Chawla\\tVisited their plant. They currently consume 44 FC domestic coal at a landed cost of ?8,400 for a 100\\tDue to the softening price trend in sponge, the buyer intends to continue with domestic coal consump\\n3\\t15-Nov-24\\tZone 8\\tSudesh\\tRajshri Iron\\tAbhishek Sharma\\tVisited their Plant. Currently consumes 45 FC domestic coal @ landed cost of ? 8100 for a 200 TPD ki\\tWe Offered 55NAR cargo at ? 10,450++ at Haldia from Dec \\x9124 Ld vsl for road delivery. \\xa0Buyer also op\\n*/'}, 'sql_query': '```sql\\nSELECT \"Action\"\\nFROM Meeting_Updates\\nWHERE \"Meeting Date\" = \\'15-Nov-24\\'\\n  AND \"Name of the person visited\" = \\'Rajeev Dalmia\\';\\n```', 'validated_sql': 'SELECT \"Action\"\\nFROM Meeting_Updates\\nWHERE \"Meeting Date\" = \\'15-Nov-24\\'\\n  AND \"Name of the person visited\" = \\'Rajeev Dalmia\\';', 'result': \"[('Expected to operational by March 2025 so we can offer 55NAR cargo from Haldia/Dhamra',)]\", 'chatbot_response': \"It looks like you're looking for information about Rajeev Dalmia's visit on November 15, 2024. According to the notes, when he visited, it was expected that operations would be up and running by March 2025, which would allow for cargo transportation from Haldia/Dhamra. Would you like me to clarify anything else about this?\"}\n"
     ]
    }
   ],
   "source": [
    "user_query = \"On 15 Nov 2024, What were the Action when Rajeev Dalmia Visited\"\n",
    "result = executor.invoke(QueryState(query=user_query))\n",
    "print(\"\\nChatbot Response:\", result)\n",
    "# Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database selected: Zone_Excel\n",
      "Table selected: Updates_&_Issues\n",
      "\n",
      "Chatbot Response: {'query': 'What are the remarks Particular for Cement Sector', 'selected_db': 'Zone_Excel', 'schema': {'Budget': '\\nCREATE TABLE \"Budget\" (\\n\\t\"Business Segment\" TEXT, \\n\\t\"Zone\" TEXT, \\n\\t\"Customer Name\" TEXT, \\n\\t\"Trader\" TEXT, \\n\\t\"Industry Segment\" TEXT, \\n\\t\"Discharge Port\" TEXT, \\n\\t\"Load Port Country\" TEXT, \\n\\t\"Grade\" TEXT, \\n\\t\"Total Sales\" TEXT\\n)\\n\\n/*\\n3 rows from Budget table:\\nBusiness Segment\\tZone\\tCustomer Name\\tTrader\\tIndustry Segment\\tDischarge Port\\tLoad Port Country\\tGrade\\tTotal Sales\\nSales\\tZone 6\\tCoastal Energen\\tSwamy\\tIPP\\tTuticorin\\tINDO\\tINDO-4200 GAR\\t2000000\\nTPH\\tZone 5\\tMeenakshi Energy\\tKasi\\tPower\\tKrishnapatnam\\tNone\\tNone\\t600000\\nSales\\tZone 6\\tIL&FS\\tSriram\\tIPP\\tKaraikal\\tINDO\\tINDO-4200 GAR\\t450000\\n*/', 'Dispatch_Market_Share': '\\nCREATE TABLE \"Dispatch_Market_Share\" (\\n\\t\"Zone\" TEXT, \\n\\t\"Port\" TEXT, \\n\\t\"Origin\" TEXT, \\n\\t\"Grade\" FLOAT, \\n\\t\"Updating Date\" DATETIME, \\n\\t\"AEL dispatch YTD (MT)\" TEXT, \\n\\t\"Competitor dispatch YTD (MT)\" TEXT, \\n\\t\"AEL dispatch Current Fortnight (MT)\" TEXT, \\n\\t\"Competitor dispatch current fortnight (MT)\" TEXT, \\n\\t\"Market share\" FLOAT\\n)\\n\\n/*\\n3 rows from Dispatch_Market_Share table:\\nZone\\tPort\\tOrigin\\tGrade\\tUpdating Date\\tAEL dispatch YTD (MT)\\tCompetitor dispatch YTD (MT)\\tAEL dispatch Current Fortnight (MT)\\tCompetitor dispatch current fortnight (MT)\\tMarket share\\nZone 7\\tGPL\\tINDO\\tNone\\t2024-12-05 00:00:00\\t498967\\t2375552\\t27288\\t159141\\tNone\\nZone 7\\tGPL\\tRSA\\tNone\\t2024-12-05 00:00:00\\t6455161884\\t3177533\\t34053\\t111166\\tNone\\nZone 7\\tGPL\\tAUS\\tNone\\t2024-12-05 00:00:00\\t205036\\t94471\\t4446\\t0\\tNone\\n*/', 'Input': '\\nCREATE TABLE \"Input\" (\\n\\t\"Input\" TEXT, \\n\\t\"Max Vessel Size\" TEXT, \\n\\t\"Ocean Frt\" FLOAT, \\n\\t\"Road Handling\" FLOAT, \\n\\t\"Rake Handing\" FLOAT, \\n\\t\"Indo Ocean Frt\" FLOAT, \\n\\t\"RSA Ocean Frt\" FLOAT, \\n\\t\"Aus Ocean Frt\" FLOAT, \\n\\t\"USA Ocean Frt\" FLOAT\\n)\\n\\n/*\\n3 rows from Input table:\\nInput\\tMax Vessel Size\\tOcean Frt\\tRoad Handling\\tRake Handing\\tIndo Ocean Frt\\tRSA Ocean Frt\\tAus Ocean Frt\\tUSA Ocean Frt\\nKPT\\tCape\\t14.0\\t475.0\\t590.0\\t8.0\\t12.0\\t12.0\\t35.0\\nKPT\\tPanamax\\tNone\\tNone\\tNone\\t9.5\\t13.75\\t13.75\\tNone\\nGoa\\tLightened cape\\t15.5\\t340.0\\t435.0\\t11.0\\tNone\\tNone\\tNone\\n*/', 'Meeting_Updates': '\\nCREATE TABLE \"Meeting_Updates\" (\\n\\t\"SI No.\" BIGINT, \\n\\t\"Meeting Date\" DATETIME, \\n\\t\"Zone\" TEXT, \\n\\t\"Trader Name\" TEXT, \\n\\t\"Customer Name\" TEXT, \\n\\t\"Name of the person visited\" TEXT, \\n\\t\"Interaction\" TEXT, \\n\\t\"Action\" TEXT\\n)\\n\\n/*\\n3 rows from Meeting_Updates table:\\nSI No.\\tMeeting Date\\tZone\\tTrader Name\\tCustomer Name\\tName of the person visited\\tInteraction\\tAction\\n1\\t2024-11-14 00:00:00\\tZone 8\\tSuraj\\tMB Sponge / MB Ispat\\tArvind Agarwal \\tVisited their plant. They consume 44 FC domestic coal at a landed cost of ₹8,400. They are setting u\\tExpected to be Offering 55NAR Cargo by Jan ’25.\\n2\\t2024-11-14 00:00:00\\tZone 8\\tSuraj\\tCP Sponge\\tKumar Chand Chawla\\tVisited their plant. They currently consume 44 FC domestic coal at a landed cost of ₹8,400 for a 100\\tDue to the softening price trend in sponge, the buyer intends to continue with domestic coal consump\\n3\\t2024-11-15 00:00:00\\tZone 8\\tSudesh\\tRajshri Iron\\tAbhishek Sharma\\tVisited their Plant. Currently consumes 45 FC domestic coal @ landed cost of ₹ 8100 for a 200 TPD ki\\tWe Offered 55NAR cargo at ₹ 10,450++ at Haldia from Dec ‘24 Ld vsl for road delivery. \\xa0Buyer also op\\n*/', 'Updates_&_Issues': '\\nCREATE TABLE \"Updates_&_Issues\" (\\n\\t\"Sr. No.\" BIGINT, \\n\\t\"Zone\" TEXT, \\n\\t\"Particulars\" TEXT, \\n\\t\"Remarks\" TEXT\\n)\\n\\n/*\\n3 rows from Updates_&_Issues table:\\nSr. No.\\tZone\\tParticulars\\tRemarks\\n1\\tZone 5\\tSponge Sector\\t1. Sponge price around Rs. 27000 - 28000 PMT. Demand has been increased, plants are running at profi\\n2\\tZone 5\\tCement Sector\\t1. No enquiry for US coal. Major Cement producers have covered with Pet coke for next 2 months\\n\\n2.Co\\n3\\tZone 5\\tIPP\\t1. Private IPPs already slowing down power production, due to low demand owning to monsoons and shif\\n*/'}, 'sql_query': \"```sql\\nSELECT Remarks \\nFROM Updates_&_Issues \\nWHERE Zone = 'Zone 5' AND Particulars = 'Cement Sector';\\n```\", 'validated_sql': \"SELECT Remarks \\nFROM Updates_&_Issues \\nWHERE Zone = 'Zone 5' AND Particulars = 'Cement Sector';\", 'result': 'Error: (sqlite3.OperationalError) near \"&\": syntax error\\n[SQL: SELECT Remarks \\nFROM Updates_&_Issues \\nWHERE Zone = \\'Zone 5\\' AND Particulars = \\'Cement Sector\\';]\\n(Background on this error at: https://sqlalche.me/e/20/e3q8)', 'chatbot_response': \"It looks like there's been an issue with the database query. I'm not able to retrieve any information about remarks for the Cement Sector in Zone 5.\\n\\nThe error message is indicating that there might be some special characters or formatting issues with the SQL query itself, rather than a problem with the data. Let me try rephrasing the question and see if we can get a better result. Can I try searching for general information about remarks related to the Cement Sector?\"}\n"
     ]
    }
   ],
   "source": [
    "user_query = \"What are the remarks Particular for Cement Sector\"\n",
    "result = executor.invoke(QueryState(query=user_query))\n",
    "print(\"\\nChatbot Response:\", result)\n",
    "# No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database selected: Customer_Portfolio\n",
      "Table selected: Customer_Portfolio\n",
      "\n",
      "Chatbot Response: {'query': 'Give me all the Customer Name of Zone 5', 'selected_db': 'Customer_Portfolio', 'schema': {'Customer_Portfolio': '\\nCREATE TABLE \"Customer_Portfolio\" (\\n\\t\"S. No.\" BIGINT, \\n\\t\"Zone\" TEXT, \\n\\t\"Account\" TEXT, \\n\\t\"Customer name\" TEXT, \\n\\t\"Category\" TEXT, \\n\\t\"Industry\" TEXT, \\n\\t\"Industry Type\" TEXT, \\n\\t\"Buying from \" TEXT, \\n\\t\"Plant location\" TEXT, \\n\\t\"Cluster location\" TEXT, \\n\\t\"State\" TEXT, \\n\\t\"1st Port\" TEXT, \\n\\t\"2nd Port\" TEXT, \\n\\t\"Logistic diff (2nd port - 1st port)\" FLOAT, \\n\\t\"Current Sponge Capacity (TPD)\" FLOAT, \\n\\t\"Expansion Capacity Current FY (TPD)\" FLOAT, \\n\\t\"Kiln Units Breakup \" TEXT, \\n\\t\"Cement Capacity (MTPA)\" TEXT, \\n\\t\"Power Capacity (MW)\" TEXT, \\n\\t\"Others/Ex Stock/FOR\" TEXT, \\n\\t\"Type of coal \" TEXT, \\n\\t\"Origin\" TEXT, \\n\\t\"Grade 1\" TEXT, \\n\\t\"Imported coal reqmnt (MTPA)\" TEXT, \\n\\t\"Domestic coal reqmnt (MTPA)\" FLOAT, \\n\\t\"Domestic mine name ( If applicable)\" TEXT, \\n\\t\"Domestic Grade ( If applicable)\" TEXT, \\n\\t\"Lifting mode\" TEXT, \\n\\t\"Customer Siding Code\" TEXT, \\n\\t\"Plant to Port Distance (By Road)\" TEXT, \\n\\t\"Specific Terms (if any)\" TEXT\\n)\\n\\n/*\\n3 rows from Customer_Portfolio table:\\nS. No.\\tZone\\tAccount\\tCustomer name\\tCategory\\tIndustry\\tIndustry Type\\tBuying from \\tPlant location\\tCluster location\\tState\\t1st Port\\t2nd Port\\tLogistic diff (2nd port - 1st port)\\tCurrent Sponge Capacity (TPD)\\tExpansion Capacity Current FY (TPD)\\tKiln Units Breakup \\tCement Capacity (MTPA)\\tPower Capacity (MW)\\tOthers/Ex Stock/FOR\\tType of coal \\tOrigin\\tGrade 1\\tImported coal reqmnt (MTPA)\\tDomestic coal reqmnt (MTPA)\\tDomestic mine name ( If applicable)\\tDomestic Grade ( If applicable)\\tLifting mode\\tCustomer Siding Code\\tPlant to Port Distance (By Road)\\tSpecific Terms (if any)\\n1\\tZone 5\\tKasi\\t Adani Wilmar \\tEnd User\\tRetail/Other\\tRetail\\tBoth\\tPentapalam\\tKrishnapatnam\\tAndhra Pradesh\\tKPT\\tEnnore\\t460.0\\t0.0\\t0.0\\tNone\\t0.00\\t0.00\\tFOR\\tSteam Coal\\tINDO\\t4800\\t 24,000 \\t0.0\\tNone\\tNone\\tRoad\\tNone\\tNone\\tNone\\n2\\tZone 5\\tKasi\\t Ambey Metallics \\tEnd User\\tSponge\\tSponge\\tBoth\\tPissurlem Goa\\tGoa\\tGoa\\t Goa \\tNMPT\\t464.8\\t100.0\\t0.0\\t1*100\\t0.00\\t0.00\\tOthers\\tSteam Coal\\tRSA\\tRB2 \\t 36,000 \\t0.0\\tNone\\tNone\\tRoad\\tNone\\tNone\\tNone\\n3\\tZone 5\\tKasi\\t BMM Ispat \\tEnd User\\tSponge\\tSponge\\tBoth\\tDhanapur\\tBellary\\tKarnataka\\t Goa \\tNMPT\\t210.2\\t2000.0\\t0.0\\t4*500\\t0.00\\t230.00\\tEx Stock\\tSteam Coal\\tRSA\\tRB2 \\t 6,00,000 \\t0.0\\tNone\\tNone\\tRake\\tNone\\tNone\\tNone\\n*/'}, 'sql_query': '```sql\\nSELECT \"Customer name\" \\nFROM Customer_Portfolio \\nWHERE Zone = \\'Zone 5\\';\\n```', 'validated_sql': 'SELECT \"Customer name\" \\nFROM Customer_Portfolio \\nWHERE Zone = \\'Zone 5\\';', 'result': \"[(' Adani Wilmar ',), (' Ambey Metallics ',), (' BMM Ispat ',), (' Grasim Harihar ',), (' Grasim Karwar',), (' Renuka sugars ',), (' Shamnur Sugars ',), (' Shraddha Ispat ',), (' Shreya Logistics ',), (' Shri Balaji Rolling Mill ',), (' Simhapuri Energy ',), (' Sundar Enterprises ',), (' Vasavadutta Cements',), (' West Coast Paper Mill ',), ('A J Coal Pvt Ltd',), ('A One Steels',), ('Adam And Coal Resources Pvt Ltd (Icl)',), ('Agarwal Coal Company',), ('Agarwal Sponge Energy',), ('Ambey Iron',), ('Anand Metalics',), ('Andhra Cements',), ('Anupam Fuels',), ('Apple Ind ',), ('Baba Akhila Sai Jyothi',), ('Bhadrashree Sponge',), ('Bilaksaria ',), ('BIOP Steels',), ('Black Gold International Pvt Ltd',), ('Chakkra Coal India Pvt Ltd',), ('Chettinad Cement Corporation Ltd',), ('Chettinad Cement Corporation Ltd',), ('Coastal Exim',), ('Dalmia Cement',), ('Dalmia Cement',), ('Deccen Cements Ltd',), ('Devi Traders',), ('Dhruvdesh Metasteels',), ('Divya Jyothi',), ('Elite Naturals',), ('Garuda Coal Agency',), ('Hanuman Traders',), ('Hindustan Calcined',), ('Hothur Ispat',), ('ILC Iron & Steels',), ('Interocean ',), ('Jairaj Ispat',), ('Janki / Transcoal',), ('Jeevaka Industries Pvt Ltd',), ('JR Metal',), ('JSW Cements Ltd',), ('JSW Energy Ltd',), ('JSW International Tradecorp Pte. Ltd.',), ('Kesari Nandan',), ('Koppal Steels',), ('Kriyas',), ('Kumar Metallurgical',), ('Mahama0v Ispat',), ('Maruti Ispat/ MS Agarwal ',), ('Minera Steels',), ('MPL Steels',), ('MS Metals',), ('MTC Business Pvt Ltd',), ('My Home Industries Industries Pvt Ltd',), ('My Home Industries Industries Pvt Ltd',), ('My Home Industries Industries Pvt Ltd',), ('Neerajaksha Iron /Siri Impex',), ('OFB Tech Pvt Ltd',), ('Om Shiva Shakti Iron Industries Pvt Ltd',), ('Orient Cement Ltd',), ('Orient Cement Ltd',), ('Padmanabh Ispat (Goa Minerals / RPA Ferro )/VLP Entp',), ('Parasakti Cement',), ('Penna Cements',), ('Penna Cements',), ('Penna Cements',), ('Penna Cements',), ('PGM Ferro',), ('Pioneer Aluminum',), ('Popuri Steels',), ('Pushpit Steels Pvt Ltd',), ('Rain Cements Ltd',), ('Rain Cements Ltd',), ('Rangineni Steels',), ('RAV Steels/Mineral Miner Trader/ Ramanjineya Ispat',), ('Rayen Steels',), ('Reactive Metals',), ('Renuka Enterprises',), ('Rupak Enterprises',), ('S J International Trading',), ('S N Coal Agency',), ('Sagar Cements Ltd',), ('Sagar Cements Ltd',), ('Sagar Cements Ltd',), ('Sagar Cements Ltd',), ('Sagar Cements Ltd',), ('Sai Balaji sponge',), ('Sai Pavan Ispat',), ('Sai Vijaya Pragati',), ('Samarth Coal Corporation',), ('SEIL Energy India Limited',), ('Shri Sai Saptagiri,',), ('SK Steel Tech',), ('SLV Steels',), ('Sree jayajothi Cements Pvt Ltd',), ('Sri Bhadrasri Steels',), ('Sri Kanakadurga Steels',), ('Sri Kanakadurga Steels',), ('Sri Krishna Minerals',), ('Sri Rama Steels & Coal',), ('Sri Sai Surya Enterprises',), ('Sri Venkateshwara Sponge Iron',), ('Sugna Sponge',), ('Sunrise Ind',), ('Sunvik Steels',), ('Suvan Steels',), ('Swastik Steels, Koppal/Tushar steels0',), ('Tanush steels ',), ('Tanush steels Unit 2',), ('Tara Enterprises',), ('Texcom Steels',), ('TGV SAARC',), ('The India Cements Ltd',), ('The India Cements Ltd',), ('The India Cements Ltd',), ('The India Cements Ltd',), ('The KCP Ltd',), ('The KCP Ltd',), ('The Ramco Cements Ltd',), ('The Ramco Cements Ltd',), ('Tirumala Enterprises',), ('Tirupati steel cast',), ('Toshiniwal Mierals',), ('Trivista Steels 0 (A One steels,)',), ('Tunics Sponge',), ('Vamshadhara Paper Mills Ltd',), ('Vanya Steels 0 (A One Steels)',), ('Venus Enterprises',), ('Vicat Kalburgi',), ('Vicat0 Barathi',), ('VIjayanagar Sugars',), ('Vinayak Steels Ltd',), ('Vinayak Steels Ltd',), ('Vishnu Barium Ltd',), ('VP Associates',), ('VRKP Sponge & Power',), ('Xindia Steels',), ('Yasin Impex India Pvt Ltd',), ('Yeshasvi Steels',), ('Zuari Cement Ltd',), ('Zuari Cement Ltd',)]\", 'chatbot_response': 'Here\\'s a natural conversational response:\\n\\n\"Okay, I\\'ve got the list of Customer Names for Zone 5. It looks like we have a total of 59 customers in this zone. Let me break it down for you:\\n\\nWe have companies like Adani Wilmar, Ambey Metallics, BMM Ispat, and many more. There are also some well-known brands like Grasim Harihar, JSW Cements Ltd, and The India Cements Ltd.\\n\\nIf you\\'d like to get a specific customer\\'s information or filter the list by any particular criteria, just let me know! I\\'m here to help.\"'}\n"
     ]
    }
   ],
   "source": [
    "user_query = \"Give me all the Customer Name of Zone 5\"\n",
    "result = executor.invoke(QueryState(query=user_query))\n",
    "print(\"\\nChatbot Response:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database selected: Stock_Ageing\n",
      "Table selected: Stock_Ageing\n",
      "\n",
      "Chatbot Response: {'query': 'What is the average aging of all stocks of Zone 1', 'selected_db': 'Stock_Ageing', 'schema': {'Stock_Ageing': '\\nCREATE TABLE \"Stock_Ageing\" (\\n\\t\"Date of updating\" TEXT, \\n\\t\"Zone\" TEXT, \\n\\t\"Port\" TEXT, \\n\\t\"Origin\" TEXT, \\n\\t\"Grade\" TEXT, \\n\\t\"Remarks\" TEXT, \\n\\t\"Vessel Name\" TEXT, \\n\\t\"Arrival Date \" TEXT, \\n\\t\"Discharge Completion Date\" TEXT, \\n\\t\"B/L Qty (MT)\" TEXT, \\n\\t\"Dispatch Qty till date (MT)\" TEXT, \\n\\t\"Today\\'s stock\" TEXT, \\n\\t\"Aging\" FLOAT, \\n\\t\"Type\" TEXT\\n)\\n\\n/*\\n3 rows from Stock_Ageing table:\\nDate of updating\\tZone\\tPort\\tOrigin\\tGrade\\tRemarks\\tVessel Name\\tArrival Date \\tDischarge Completion Date\\tB/L Qty (MT)\\tDispatch Qty till date (MT)\\tToday\\'s stock\\tAging\\tType\\n6-Dec-24\\tZone 1\\tTUNA\\tUSA\\tUS (6900)-401\\tNone\\tMV MARAN MARINER\\t11-May-24\\t24-May-24\\t1,23,712\\t1,08,776\\t14,936\\t192.0\\tSNS\\n6-Dec-24\\tZone 1\\tTUNA\\tUSA\\tUS (6900)-401\\tNone\\tMV KM OSAKA\\t12-Jul-24\\t13-Jul-24\\t66,137\\t0\\t66,137\\t142.0\\tSNS\\n6-Dec-24\\tZone 1\\tTUNA\\tUSA\\tUS (6900)-401\\tNone\\tMV FLAG SEAMAN\\t22-07-24\\t28-Jul-24\\t1,22,180\\t0\\t1,22,180\\t127.0\\tSNS\\n*/'}, 'sql_query': \"```sql\\nSELECT AVG(T1.Aging) \\nFROM Stock_Ageing AS T1 \\nWHERE T1.Zone = 'Zone 1'\\n```\", 'validated_sql': \"SELECT AVG(T1.Aging) \\nFROM Stock_Ageing AS T1 \\nWHERE T1.Zone = 'Zone 1'\", 'result': '[(133.0,)]', 'chatbot_response': \"The average age of all stock in Zone 1 is approximately 133 years! That's quite impressive (or perhaps concerning?) for a zone that's likely home to many long-lived and possibly iconic stocks. Would you like me to break down the data further or compare it with other zones?\"}\n"
     ]
    }
   ],
   "source": [
    "user_query = \"What is the average aging of all stocks of Zone 1\"\n",
    "result = executor.invoke(QueryState(query=user_query))\n",
    "print(\"\\nChatbot Response:\", result)\n",
    "# Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database selected: Meeting_Updates\n",
      "Table selected: Meeting_Updates\n",
      "\n",
      "Chatbot Response: {'query': 'What is the action for 14 Nov 2024 in Zone 8  with Customer CB Sponge', 'selected_db': 'Meeting_Updates', 'schema': {'Meeting_Updates': '\\nCREATE TABLE \"Meeting_Updates\" (\\n\\t\"SI No.\" TEXT, \\n\\t\"Meeting Date\" TEXT, \\n\\t\"Zone\" TEXT, \\n\\t\"Trader Name\" TEXT, \\n\\t\"Customer Name\" TEXT, \\n\\t\"Name of the person visited\" TEXT, \\n\\t\"Interaction\" TEXT, \\n\\t\"Action\" TEXT\\n)\\n\\n/*\\n3 rows from Meeting_Updates table:\\nSI No.\\tMeeting Date\\tZone\\tTrader Name\\tCustomer Name\\tName of the person visited\\tInteraction\\tAction\\n1\\t14-Nov-24\\tZone 8\\tSuraj\\tMB Sponge / MB Ispat\\tArvind Agarwal \\tVisited their plant. They consume 44 FC domestic coal at a landed cost of ?8,400. They are setting u\\tExpected to be Offering 55NAR Cargo by Jan \\x9225.\\n2\\t14-Nov-24\\tZone 8\\tSuraj\\tCP Sponge\\tKumar Chand Chawla\\tVisited their plant. They currently consume 44 FC domestic coal at a landed cost of ?8,400 for a 100\\tDue to the softening price trend in sponge, the buyer intends to continue with domestic coal consump\\n3\\t15-Nov-24\\tZone 8\\tSudesh\\tRajshri Iron\\tAbhishek Sharma\\tVisited their Plant. Currently consumes 45 FC domestic coal @ landed cost of ? 8100 for a 200 TPD ki\\tWe Offered 55NAR cargo at ? 10,450++ at Haldia from Dec \\x9124 Ld vsl for road delivery. \\xa0Buyer also op\\n*/'}, 'sql_query': '```sql\\nSELECT Action \\nFROM Meeting_Updates \\nWHERE \"Meeting Date\" = \\'14-Nov-24\\' AND Zone = \\'Zone 8\\' AND Customer Name = \\'CB Sponge\\';\\n```', 'validated_sql': 'SELECT Action \\nFROM Meeting_Updates \\nWHERE \"Meeting Date\" = \\'14-Nov-24\\' AND Zone = \\'Zone 8\\' AND Customer Name = \\'CB Sponge\\';', 'result': 'Error: (sqlite3.OperationalError) near \"Name\": syntax error\\n[SQL: SELECT Action \\nFROM Meeting_Updates \\nWHERE \"Meeting Date\" = \\'14-Nov-24\\' AND Zone = \\'Zone 8\\' AND Customer Name = \\'CB Sponge\\';]\\n(Background on this error at: https://sqlalche.me/e/20/e3q8)', 'chatbot_response': 'It looks like there\\'s been an issue with the database query. I\\'m getting an error message that says there\\'s a syntax problem with the SQL code.\\n\\nLet me take another look at it... Ah, yes! It seems like the issue is with the column name \"Customer Name\". In SQL, column names can\\'t have spaces in them. It looks like we need to adjust the query to use a different column name that doesn\\'t have any spaces.\\n\\nWould you like me to try running the query again with some adjustments?'}\n"
     ]
    }
   ],
   "source": [
    "user_query = \"What is the action for 14 Nov 2024 in Zone 8  with Customer CB Sponge\"\n",
    "result = executor.invoke(QueryState(query=user_query))\n",
    "print(\"\\nChatbot Response:\", result)\n",
    "# No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database selected: atmspl_trip_details\n",
      "Table selected: atmspl_trip_details\n"
     ]
    }
   ],
   "source": [
    "user_query = \"What is the time taken between sjq arrival and sjq departure for vehicle id = 51154\"\n",
    "result = executor.invoke(QueryState(query=user_query))\n",
    "print(\"\\nChatbot Response:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database selected: Sales_&_Enquiry\n",
      "Table selected: Sales_&_Enquiry\n",
      "\n",
      "Chatbot Response: {'query': 'How many Sales & Enquiry are concluded', 'selected_db': 'Sales_&_Enquiry', 'schema': {'Sales_&_Enquiry': '\\nCREATE TABLE \"Sales_&_Enquiry\" (\\n\\t\"S. No\" BIGINT, \\n\\t\"FY\" TEXT, \\n\\t\"Enquiry Month\" TEXT, \\n\\t\"Zone\" TEXT, \\n\\t\"Trader Name\" TEXT, \\n\\t\"Status (Concluded/Lost/Dropped)\" TEXT, \\n\\t\"Name of the Customer\" TEXT, \\n\\t\"Trader/End User\" TEXT, \\n\\t\"Date\" TEXT, \\n\\t\"Enquiry Qty (MT)\" FLOAT, \\n\\t\"Grade\" TEXT, \\n\\t\"Low/Mid/High\" TEXT, \\n\\t\"Origin\" TEXT, \\n\\t\"Concluded basis \" TEXT, \\n\\t\"Concluded port\" TEXT, \\n\\t\"Supplier Name\" TEXT, \\n\\t\"Concluded Rate (Rs/$)\" TEXT, \\n\\t\"Concluded Cargo\" TEXT, \\n\\t\"Discounted sector (Yes/No)\" TEXT, \\n\\t\"Discounted sector(Name)\" TEXT, \\n\\t\"Adani Offered Rate\" TEXT, \\n\\t\"Adani Offered Cargo\" TEXT, \\n\\t\"Competitor Concluded Rate\" TEXT, \\n\\t\"Deal with Adani/Non Adani\" TEXT, \\n\\t\"Concluded With (Competitor)\" TEXT, \\n\\t\"Reason\" TEXT, \\n\\t\"Detailed Reasons if any\" TEXT, \\n\\t\"Remarks 1\" FLOAT, \\n\\t\"Remarks 2\" FLOAT\\n)\\n\\n/*\\n3 rows from Sales_&_Enquiry table:\\nS. No\\tFY\\tEnquiry Month\\tZone\\tTrader Name\\tStatus (Concluded/Lost/Dropped)\\tName of the Customer\\tTrader/End User\\tDate\\tEnquiry Qty (MT)\\tGrade\\tLow/Mid/High\\tOrigin\\tConcluded basis \\tConcluded port\\tSupplier Name\\tConcluded Rate (Rs/$)\\tConcluded Cargo\\tDiscounted sector (Yes/No)\\tDiscounted sector(Name)\\tAdani Offered Rate\\tAdani Offered Cargo\\tCompetitor Concluded Rate\\tDeal with Adani/Non Adani\\tConcluded With (Competitor)\\tReason\\tDetailed Reasons if any\\tRemarks 1\\tRemarks 2\\n1\\tFY 24-25\\tApril\\'24\\tZone 6\\tSriram\\tLost\\tCHETTINAD CEMENT CORPORATION LTD\\tEnd User\\t26-Mar-24\\t50000.0\\tKBB (3400) - 3510\\tLOW\\tIndo \\tOTHERS \\tKaraikal\\tENR\\tUSD 49.50\\tINDO 34\\tNO\\tNO\\tNO CARGO\\tNO CARGO\\tNone\\tNon Adani\\tNone\\tCargo not available\\tNO CARGO\\tNone\\tNone\\n2\\tFY 24-25\\tApril\\'24\\tZone 6\\tSriram\\tLost\\tCHETTINAD CEMENT CORPORATION LTD\\tEnd User\\t26-Mar-24\\t50000.0\\tPTBA (5000) - 3323\\tHIGH\\tIndo \\tOTHERS \\tKaraikal\\tENR\\tUSD 81.50\\tIndo 5000 \\tNO\\tNO\\tUSD 97.5\\tIndo 50\\tNone\\tNon Adani\\tNone\\tPrice\\tPricing\\tNone\\tNone\\n3\\tFY 24-25\\tMay\\'24\\tZone 5\\tSriram\\tLost\\tJSW ENERGY LTD\\tNone\\t28-Mar-24\\t150000.0\\tRUS 6000\\tHIGH\\tRussia\\tOTHERS \\tJaigad\\tNone\\tUSD 102\\tRus 6000\\tNO\\tNO\\tUSD 87.05\\tIndo 50\\tNone\\tNon Adani\\tNone\\tPrice\\tPricing\\tNone\\tNone\\n*/'}, 'sql_query': \"```sql\\nSELECT COUNT(*)\\nFROM Sales_&_Enquiry\\nWHERE Status (Concluded/Lost/Dropped) = 'Concluded';\\n```\", 'validated_sql': \"SELECT COUNT(*)\\nFROM Sales_&_Enquiry\\nWHERE Status = 'Concluded';\", 'result': 'Error: (sqlite3.OperationalError) near \"&\": syntax error\\n[SQL: SELECT COUNT(*)\\nFROM Sales_&_Enquiry\\nWHERE Status = \\'Concluded\\';]\\n(Background on this error at: https://sqlalche.me/e/20/e3q8)', 'chatbot_response': 'It looks like there\\'s been an issue with the SQL query. The error message is saying that it doesn\\'t recognize the \"&\" symbol in the table name \"Sales_&_Enquiry\". This is likely because SQLite (the database system being used) doesn\\'t allow special characters like \"_\" and \"&\" to be used directly in table names.\\n\\nLet me try rephrasing your question to see if we can get a more accurate answer. Can you tell me what you\\'re trying to find out? Are you looking for the number of sales or enquiries that have been concluded, perhaps?'}\n"
     ]
    }
   ],
   "source": [
    "user_query = \"How many Sales & Enquiry are concluded\"\n",
    "result = executor.invoke(QueryState(query=user_query))\n",
    "print(\"\\nChatbot Response:\", result)\n",
    "# No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database selected: atmspl_trip_details\n",
      "\n",
      "Chatbot Response: {'query': 'How many transporter are ATMSL?', 'selected_db': 'atmspl_trip_details', 'schema': {'atmspl_trip_details': '\\nCREATE TABLE atmspl_trip_details (\\n\\tsn BIGINT, \\n\\ttransporter TEXT, \\n\\tid BIGINT, \\n\\tvehicle_id BIGINT, \\n\\ttrip_date TEXT, \\n\\tvehicle_type TEXT, \\n\\tvehicle BIGINT, \\n\\twagon_no FLOAT, \\n\\tn_box_no TEXT, \\n\\tengine_no TEXT, \\n\\trake_no BIGINT, \\n\\tfnr_no BIGINT, \\n\\tcoal_type TEXT, \\n\\tdestination TEXT, \\n\\tlast_siding_location TEXT, \\n\\tno_of_extraneous_wagon BIGINT, \\n\\tdevice_attachment_location TEXT, \\n\\tsjq_arrival TEXT, \\n\\tsjq_departure TEXT, \\n\\tsjq_idle_hrs FLOAT, \\n\\tavg_speed_sjq_pasla FLOAT, \\n\\tempty_pasla_in TEXT, \\n\\tempty_pasla_out TEXT, \\n\\tempty_pasla_gap FLOAT, \\n\\tavg_speed_pasla_sonpur FLOAT, \\n\\tempty_sonpur_in TEXT, \\n\\tavg_speed_ramanujnagar_sonpur FLOAT, \\n\\tround_trip_distance FLOAT, \\n\\tround_trip_duration BIGINT, \\n\\tcomments TEXT, \\n\\tis_internal TEXT\\n)\\n\\n/*\\n3 rows from atmspl_trip_details table:\\nsn\\ttransporter\\tid\\tvehicle_id\\ttrip_date\\tvehicle_type\\tvehicle\\twagon_no\\tn_box_no\\tengine_no\\trake_no\\tfnr_no\\tcoal_type\\tdestination\\tlast_siding_location\\tno_of_extraneous_wagon\\tdevice_attachment_location\\tsjq_arrival\\tsjq_departure\\tsjq_idle_hrs\\tavg_speed_sjq_pasla\\tempty_pasla_in\\tempty_pasla_out\\tempty_pasla_gap\\tavg_speed_pasla_sonpur\\tempty_sonpur_in\\tavg_speed_ramanujnagar_sonpur\\tround_trip_distance\\tround_trip_duration\\tcomments\\tis_internal\\n4\\tATMSL\\t10036288\\t51053\\t01-07-2024\\tRake\\t90759084\\t22121447472.0\\tSGNE 109\\t32721\\t16077\\t24063014655\\tWashed\\tChhabra\\tNone\\t0\\tSJQ Surajpur\\t01-07-2024 09:30\\t01-07-2024 09:33\\t3.0\\t12.0\\t01-07-2024 09:34\\t01-07-2024 09:38\\t3.0\\t47.14\\t01-07-2024 09:52\\t52.88\\t166.52\\t3748\\tDevice Installed\\tYes\\n2\\tATMSL\\t10036353\\t51169\\t01-07-2024\\tRake\\t92428571\\t12160530938.0\\t849\\t31306\\t16074\\t24063014549\\tWashed\\tKalisindh\\tNone\\t0\\tSJQ Surajpur\\t01-07-2024 06:59\\t01-07-2024 07:02\\t2.0\\t12.0\\t01-07-2024 07:03\\t01-07-2024 07:06\\t3.0\\t55.0\\t01-07-2024 07:19\\t52.88\\t158.87\\t640\\tDevice Installed\\tYes\\n3\\tATMSL\\t10036984\\t51154\\t01-07-2024\\tRake\\t92435345\\t10079671919.0\\t860\\t60409\\t16076\\t24063014619\\tWashed\\tChhabra\\tNone\\t0\\tSJQ Surajpur\\t01-07-2024 08:29\\t01-07-2024 08:32\\t3.0\\t12.0\\t01-07-2024 08:34\\t01-07-2024 08:37\\t3.0\\t55.0\\t01-07-2024 08:49\\t47.0\\t156.21\\t764\\tDevice Installed\\tYes\\n*/'}, 'sql_query': \"```sql\\nSELECT COUNT(sn)\\nFROM atmspl_trip_details\\nWHERE transporter = 'ATMSL';\\n```\", 'validated_sql': \"SELECT COUNT(sn)\\nFROM atmspl_trip_details\\nWHERE transporter = 'ATMSL';\", 'result': '[(4,)]', 'chatbot_response': 'The number of transporters that are ATMSL is 4. Would you like to know more about what ATMSL means or how these transporters operate?'}\n"
     ]
    }
   ],
   "source": [
    "user_query = \"How many transporter are ATMSL?\"\n",
    "result = executor.invoke(QueryState(query=user_query))\n",
    "print(\"\\nChatbot Response:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn which district, Suratgarh Junction is located in Landmarks? HANUMANGARH\\nWhat is the total running average speed of all TPS in TPS Trips? 21.35km/h\\nHow many transporter ar ATMSL? \\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "In which district, Suratgarh Junction is located in Landmarks? HANUMANGARH\n",
    "What is the total running average speed of all TPS in TPS Trips? 21.35km/h\n",
    "How many transporter are ATMSL? 4\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
